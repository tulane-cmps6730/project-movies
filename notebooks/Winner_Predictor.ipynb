{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import GPT2Model, GPT2Config, GPT2Tokenizer\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import pandas as pd\n",
    "\n",
    "# Assuming new_df_with_game_data is the DataFrame created using your consolidate_game_data function\n",
    "\n",
    "class GameDataset(Dataset):\n",
    "    def __init__(self, encodings, labels):\n",
    "        self.encodings = encodings\n",
    "        self.labels = labels\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
    "        item['labels'] = torch.tensor(self.labels[idx])\n",
    "        return item\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "# Load tokenizer\n",
    "tokenizer = GPT2Tokenizer.from_pretrained('gpt2')\n",
    "\n",
    "# Preprocess text data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the pad token to the eos_token if it's not already set\n",
    "if tokenizer.pad_token is None:\n",
    "    tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "# Now your tokenizer call should work without errors\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df_with_game_data = pd.read_csv(\"./Data/Winners.csv\")\n",
    "texts = new_df_with_game_data['GameText'].tolist()\n",
    "labels = new_df_with_game_data['WinningTeam']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = new_df_with_game_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encodings = tokenizer(texts, truncation=True, padding=True, max_length=1024)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>GameID</th>\n",
       "      <th>GameText</th>\n",
       "      <th>WinningTeam</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2015-10-27_CLE_CHI</td>\n",
       "      <td>720 Jump ball: P. Gasol vs. T. Mozgov (D. Rose...</td>\n",
       "      <td>CHI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2015-10-27_DET_ATL</td>\n",
       "      <td>720 Jump ball: A. Drummond vs. A. Horford (E. ...</td>\n",
       "      <td>DET</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2015-10-27_NOP_GSW</td>\n",
       "      <td>720 Jump ball: A. Bogut vs. A. Davis (N. Robin...</td>\n",
       "      <td>GSW</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2015-10-28_CHI_BRK</td>\n",
       "      <td>720 Jump ball: P. Gasol vs. B. Lopez (T. Young...</td>\n",
       "      <td>CHI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2015-10-28_CHO_MIA</td>\n",
       "      <td>720 Jump ball: A. Jefferson vs. H. Whiteside (...</td>\n",
       "      <td>MIA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1311</th>\n",
       "      <td>2016-06-08_GSW_CLE</td>\n",
       "      <td>720 Jump ball: A. Bogut vs. T. Thompson (K. Th...</td>\n",
       "      <td>CLE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1312</th>\n",
       "      <td>2016-06-10_GSW_CLE</td>\n",
       "      <td>720 Jump ball: A. Bogut vs. T. Thompson (S. Cu...</td>\n",
       "      <td>GSW</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1313</th>\n",
       "      <td>2016-06-13_CLE_GSW</td>\n",
       "      <td>720 Jump ball: A. Bogut vs. T. Thompson (S. Cu...</td>\n",
       "      <td>CLE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1314</th>\n",
       "      <td>2016-06-16_GSW_CLE</td>\n",
       "      <td>720 Jump ball: D. Green vs. T. Thompson (K. Lo...</td>\n",
       "      <td>CLE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1315</th>\n",
       "      <td>2016-06-19_CLE_GSW</td>\n",
       "      <td>720 Jump ball: F. Ezeli vs. T. Thompson (L. Ja...</td>\n",
       "      <td>CLE</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1316 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  GameID                                           GameText  \\\n",
       "0     2015-10-27_CLE_CHI  720 Jump ball: P. Gasol vs. T. Mozgov (D. Rose...   \n",
       "1     2015-10-27_DET_ATL  720 Jump ball: A. Drummond vs. A. Horford (E. ...   \n",
       "2     2015-10-27_NOP_GSW  720 Jump ball: A. Bogut vs. A. Davis (N. Robin...   \n",
       "3     2015-10-28_CHI_BRK  720 Jump ball: P. Gasol vs. B. Lopez (T. Young...   \n",
       "4     2015-10-28_CHO_MIA  720 Jump ball: A. Jefferson vs. H. Whiteside (...   \n",
       "...                  ...                                                ...   \n",
       "1311  2016-06-08_GSW_CLE  720 Jump ball: A. Bogut vs. T. Thompson (K. Th...   \n",
       "1312  2016-06-10_GSW_CLE  720 Jump ball: A. Bogut vs. T. Thompson (S. Cu...   \n",
       "1313  2016-06-13_CLE_GSW  720 Jump ball: A. Bogut vs. T. Thompson (S. Cu...   \n",
       "1314  2016-06-16_GSW_CLE  720 Jump ball: D. Green vs. T. Thompson (K. Lo...   \n",
       "1315  2016-06-19_CLE_GSW  720 Jump ball: F. Ezeli vs. T. Thompson (L. Ja...   \n",
       "\n",
       "     WinningTeam  \n",
       "0            CHI  \n",
       "1            DET  \n",
       "2            GSW  \n",
       "3            CHI  \n",
       "4            MIA  \n",
       "...          ...  \n",
       "1311         CLE  \n",
       "1312         GSW  \n",
       "1313         CLE  \n",
       "1314         CLE  \n",
       "1315         CLE  \n",
       "\n",
       "[1316 rows x 3 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_df_with_game_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25801"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(new_df_with_game_data.iloc[0].GameText)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       CHI\n",
       "1       DET\n",
       "2       GSW\n",
       "3       CHI\n",
       "4       MIA\n",
       "       ... \n",
       "1311    CLE\n",
       "1312    GSW\n",
       "1313    CLE\n",
       "1314    CLE\n",
       "1315    CLE\n",
       "Name: WinningTeam, Length: 1316, dtype: object"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of texts: 1316\n",
      "Length of labels: 2\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'dict' object has no attribute 'input_ids'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[15], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLength of texts: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(texts)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLength of labels: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(labels)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m----> 4\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLength of encodings: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(\u001b[43mencodings\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minput_ids\u001b[49m)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      6\u001b[0m \u001b[38;5;66;03m# Ensure that the texts, labels, and encodings have the same number of samples\u001b[39;00m\n\u001b[1;32m      7\u001b[0m min_samples \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmin\u001b[39m(\u001b[38;5;28mlen\u001b[39m(texts), \u001b[38;5;28mlen\u001b[39m(labels), \u001b[38;5;28mlen\u001b[39m(encodings\u001b[38;5;241m.\u001b[39minput_ids))\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'dict' object has no attribute 'input_ids'"
     ]
    }
   ],
   "source": [
    "# Check the lengths of the input variables\n",
    "print(f\"Length of texts: {len(texts)}\")\n",
    "print(f\"Length of labels: {len(labels)}\")\n",
    "print(f\"Length of encodings: {len(encodings.input_ids)}\")\n",
    "\n",
    "# Ensure that the texts, labels, and encodings have the same number of samples\n",
    "min_samples = min(len(texts), len(labels), len(encodings.input_ids))\n",
    "texts = texts[:min_samples]\n",
    "labels = labels[:min_samples]\n",
    "encodings.input_ids = encodings.input_ids[:min_samples]\n",
    "encodings.attention_mask = encodings.attention_mask[:min_samples]\n",
    "\n",
    "# Split data into train and validation sets\n",
    "train_encodings, val_encodings, train_labels, val_labels = train_test_split(\n",
    "    encodings, labels, test_size=0.1, random_state=42)\n",
    "\n",
    "# Create Dataset and DataLoader for training and validation\n",
    "train_dataset = GameDataset(train_encodings, train_labels)\n",
    "val_dataset = GameDataset(val_encodings, val_labels)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=8, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=8)\n",
    "\n",
    "# Load GPT-2 model and set up training\n",
    "configuration = GPT2Config.from_pretrained('gpt2', n_class=len(label_encoder.classes_))\n",
    "model = GPT2Model(configuration)\n",
    "model.classifier = torch.nn.Linear(configuration.n_embd, configuration.n_class)\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=1e-5)\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "# Training loop would go here (not provided in this snippet)\n",
    "# ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_pretrained('path/to/save/model')\n",
    "tokenizer.save_pretrained('path/to/save/tokenizer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>GameID</th>\n",
       "      <th>GameText</th>\n",
       "      <th>WinningTeam</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2015-10-27_CLE_CHI</td>\n",
       "      <td>720 Jump ball: P. Gasol vs. T. Mozgov (D. Rose...</td>\n",
       "      <td>CHI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2015-10-27_DET_ATL</td>\n",
       "      <td>720 Jump ball: A. Drummond vs. A. Horford (E. ...</td>\n",
       "      <td>DET</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2015-10-27_NOP_GSW</td>\n",
       "      <td>720 Jump ball: A. Bogut vs. A. Davis (N. Robin...</td>\n",
       "      <td>GSW</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2015-10-28_CHI_BRK</td>\n",
       "      <td>720 Jump ball: P. Gasol vs. B. Lopez (T. Young...</td>\n",
       "      <td>CHI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2015-10-28_CHO_MIA</td>\n",
       "      <td>720 Jump ball: A. Jefferson vs. H. Whiteside (...</td>\n",
       "      <td>MIA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1311</th>\n",
       "      <td>2016-06-08_GSW_CLE</td>\n",
       "      <td>720 Jump ball: A. Bogut vs. T. Thompson (K. Th...</td>\n",
       "      <td>CLE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1312</th>\n",
       "      <td>2016-06-10_GSW_CLE</td>\n",
       "      <td>720 Jump ball: A. Bogut vs. T. Thompson (S. Cu...</td>\n",
       "      <td>GSW</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1313</th>\n",
       "      <td>2016-06-13_CLE_GSW</td>\n",
       "      <td>720 Jump ball: A. Bogut vs. T. Thompson (S. Cu...</td>\n",
       "      <td>CLE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1314</th>\n",
       "      <td>2016-06-16_GSW_CLE</td>\n",
       "      <td>720 Jump ball: D. Green vs. T. Thompson (K. Lo...</td>\n",
       "      <td>CLE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1315</th>\n",
       "      <td>2016-06-19_CLE_GSW</td>\n",
       "      <td>720 Jump ball: F. Ezeli vs. T. Thompson (L. Ja...</td>\n",
       "      <td>CLE</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1316 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  GameID                                           GameText  \\\n",
       "0     2015-10-27_CLE_CHI  720 Jump ball: P. Gasol vs. T. Mozgov (D. Rose...   \n",
       "1     2015-10-27_DET_ATL  720 Jump ball: A. Drummond vs. A. Horford (E. ...   \n",
       "2     2015-10-27_NOP_GSW  720 Jump ball: A. Bogut vs. A. Davis (N. Robin...   \n",
       "3     2015-10-28_CHI_BRK  720 Jump ball: P. Gasol vs. B. Lopez (T. Young...   \n",
       "4     2015-10-28_CHO_MIA  720 Jump ball: A. Jefferson vs. H. Whiteside (...   \n",
       "...                  ...                                                ...   \n",
       "1311  2016-06-08_GSW_CLE  720 Jump ball: A. Bogut vs. T. Thompson (K. Th...   \n",
       "1312  2016-06-10_GSW_CLE  720 Jump ball: A. Bogut vs. T. Thompson (S. Cu...   \n",
       "1313  2016-06-13_CLE_GSW  720 Jump ball: A. Bogut vs. T. Thompson (S. Cu...   \n",
       "1314  2016-06-16_GSW_CLE  720 Jump ball: D. Green vs. T. Thompson (K. Lo...   \n",
       "1315  2016-06-19_CLE_GSW  720 Jump ball: F. Ezeli vs. T. Thompson (L. Ja...   \n",
       "\n",
       "     WinningTeam  \n",
       "0            CHI  \n",
       "1            DET  \n",
       "2            GSW  \n",
       "3            CHI  \n",
       "4            MIA  \n",
       "...          ...  \n",
       "1311         CLE  \n",
       "1312         GSW  \n",
       "1313         CLE  \n",
       "1314         CLE  \n",
       "1315         CLE  \n",
       "\n",
       "[1316 rows x 3 columns]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Trying Long Transformer now"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "39ce618abeca4679a6ad3e8fc37e5578",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model.bin:   0%|          | 0.00/597M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of LongformerForSequenceClassification were not initialized from the model checkpoint at allenai/longformer-base-4096 and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/Users/gavingalusha/NLP/ggalusha/project/project-movies/nlp-virtual/lib/python3.10/site-packages/transformers/optimization.py:457: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LongformerForSequenceClassification(\n",
       "  (longformer): LongformerModel(\n",
       "    (embeddings): LongformerEmbeddings(\n",
       "      (word_embeddings): Embedding(50265, 768, padding_idx=1)\n",
       "      (token_type_embeddings): Embedding(1, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "      (position_embeddings): Embedding(4098, 768, padding_idx=1)\n",
       "    )\n",
       "    (encoder): LongformerEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-11): 12 x LongformerLayer(\n",
       "          (attention): LongformerAttention(\n",
       "            (self): LongformerSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (query_global): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key_global): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value_global): Linear(in_features=768, out_features=768, bias=True)\n",
       "            )\n",
       "            (output): LongformerSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): LongformerIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): LongformerOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (classifier): LongformerClassificationHead(\n",
       "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "    (out_proj): Linear(in_features=768, out_features=30, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import LongformerTokenizer, LongformerForSequenceClassification, AdamW\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Load tokenizer and model\n",
    "tokenizer = LongformerTokenizer.from_pretrained('allenai/longformer-base-4096')\n",
    "\n",
    "# Assuming df is your DataFrame and has the columns 'text' for inputs and 'label' for outputs\n",
    "texts = df['GameText'].tolist()\n",
    "labels = LabelEncoder().fit_transform(df['WinningTeam'])  # Encode labels numerically\n",
    "\n",
    "# Set the number of unique labels for the classifier\n",
    "num_labels = len(set(labels))\n",
    "\n",
    "# Tokenize text with a higher max_length\n",
    "encodings = tokenizer(texts, max_length=4096, truncation=True, padding=\"max_length\", return_tensors=\"pt\")\n",
    "\n",
    "# Split data\n",
    "train_texts, val_texts, train_labels, val_labels = train_test_split(encodings['input_ids'], labels, test_size=0.1)\n",
    "\n",
    "# Create PyTorch dataset\n",
    "class TextDataset(Dataset):\n",
    "    def __init__(self, encodings, labels):\n",
    "        self.encodings = encodings\n",
    "        self.labels = labels\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = {'input_ids': self.encodings[idx], 'labels': self.labels[idx]}\n",
    "        return item\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "train_dataset = TextDataset(train_texts, train_labels)\n",
    "val_dataset = TextDataset(val_texts, val_labels)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=4, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=4)\n",
    "\n",
    "# Load Longformer model configured for sequence classification with the correct number of labels\n",
    "model = LongformerForSequenceClassification.from_pretrained('allenai/longformer-base-4096', num_labels=num_labels)\n",
    "\n",
    "# Prepare for training\n",
    "optimizer = AdamW(model.parameters(), lr=1e-5)\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "# Set up device\n",
    "device = torch.device(\"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "\n",
    "# Save the model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating subset datasets for just the first 10 instances for quick testing\n",
    "subset_train_texts = train_texts[:10]  # First 10 instances\n",
    "subset_train_labels = train_labels[:10]\n",
    "\n",
    "# Create dataset and DataLoader for the subset\n",
    "subset_train_dataset = TextDataset(subset_train_texts, subset_train_labels)\n",
    "subset_train_loader = DataLoader(subset_train_dataset, batch_size=4, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 3.356382369995117\n",
      "Loss: 3.440417528152466\n",
      "Loss: 3.570096492767334\n"
     ]
    }
   ],
   "source": [
    "optimizer = AdamW(model.parameters(), lr=1e-5)\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "# Example of a mini-training loop for the subset\n",
    "for batch in subset_train_loader:\n",
    "    optimizer.zero_grad()\n",
    "    input_ids = batch['input_ids'].to(device)\n",
    "    labels = batch['labels'].to(device)\n",
    "    outputs = model(input_ids=input_ids, labels=labels)\n",
    "    loss = outputs.loss\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    print(f\"Loss: {loss.item()}\")\n",
    "\n",
    "# Saving the model if needed\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Assuming 'df' contains your dataset and 'WinningTeam' is the column with labels\n",
    "labels = df['WinningTeam']  # Extract labels from the DataFrame\n",
    "\n",
    "# Create a label encoder object\n",
    "label_encoder = LabelEncoder()\n",
    "\n",
    "# Fit label encoder and transform labels into numbers\n",
    "encoded_labels = label_encoder.fit_transform(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted Winner: HOU\n",
      "Prediction Confidence: 0.0442\n"
     ]
    }
   ],
   "source": [
    "def predict_winner(text, model, tokenizer, label_encoder):\n",
    "    # Ensure model is in evaluation mode\n",
    "    model.eval()\n",
    "\n",
    "    # Tokenize the text\n",
    "    encoding = tokenizer(text, return_tensors=\"pt\", padding=\"max_length\", truncation=True, max_length=4096)\n",
    "\n",
    "    # Move the tensor to the same device as the model\n",
    "    input_ids = encoding['input_ids'].to(model.device)\n",
    "    attention_mask = encoding['attention_mask'].to(model.device)\n",
    "\n",
    "    # Predict\n",
    "    with torch.no_grad():\n",
    "        outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        logits = outputs.logits\n",
    "\n",
    "    # Convert logits to probabilities (optional)\n",
    "    probabilities = torch.nn.functional.softmax(logits, dim=-1)\n",
    "\n",
    "    # Get the predicted class index\n",
    "    predicted_index = torch.argmax(probabilities, dim=-1).item()\n",
    "\n",
    "    # Decode the predicted index to the class label\n",
    "    predicted_label = label_encoder.inverse_transform([predicted_index])[0]\n",
    "\n",
    "    return predicted_label, probabilities[0, predicted_index].item()\n",
    "\n",
    "# Example usage\n",
    "model.to(\"cpu\")  # Ensure the model is on CPU if not using GPU for prediction\n",
    "single_test_example = df['GameText'].iloc[-4]\n",
    "predicted_winner, confidence = predict_winner(single_test_example, model, tokenizer, label_encoder)\n",
    "\n",
    "print(f\"Predicted Winner: {predicted_winner}\")\n",
    "print(f\"Prediction Confidence: {confidence:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training loop\n",
    "\n",
    "\n",
    "\n",
    "epochs = 3\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    for batch in train_loader:\n",
    "        input_ids = batch['input_ids'].to(device)\n",
    "        labels = batch['labels'].to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(input_ids=input_ids, labels=labels)\n",
    "        loss = outputs.loss\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "\n",
    "    avg_train_loss = total_loss / len(train_loader)\n",
    "    print(f\"Training loss for epoch {epoch + 1}: {avg_train_loss}\")\n",
    "\n",
    "    # Validation phase\n",
    "    model.eval()\n",
    "    total_eval_loss = 0\n",
    "    total_eval_accuracy = 0\n",
    "    for batch in val_loader:\n",
    "        input_ids = batch['input_ids'].to(device)\n",
    "        labels = batch['labels'].to(device)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            outputs = model(input_ids=input_ids, labels=labels)\n",
    "\n",
    "        loss = outputs.loss\n",
    "        total_eval_loss += loss.item()\n",
    "\n",
    "        logits = outputs.logits\n",
    "        predictions = torch.argmax(logits, dim=-1)\n",
    "        total_eval_accuracy += (predictions == labels).float().mean()\n",
    "\n",
    "    avg_val_loss = total_eval_loss / len(val_loader)\n",
    "    avg_val_accuracy = total_eval_accuracy / len(val_loader)\n",
    "    print(f\"Validation Loss: {avg_val_loss}\")\n",
    "    print(f\"Validation Accuracy: {avg_val_accuracy}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp-virtual",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
