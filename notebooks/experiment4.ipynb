{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 names  release_year maturity_rating duration  \\\n",
      "0        Mission Majnu          2023        U/A 16+     2h 9m   \n",
      "1               Cirkus          2022         U/A 7+    2h 14m   \n",
      "2  Gangubai Kathiawadi          2022        U/A 16+    2h 33m   \n",
      "3              Thunivu          2023        U/A 16+    2h 22m   \n",
      "4    Bhool Bhulaiyaa 2          2022        U/A 13+    2h 21m   \n",
      "\n",
      "                                         description  \\\n",
      "0  In the 1970s, an undercover Indian spy takes o...   \n",
      "1  Chaos and comedy take the spotlight when a rin...   \n",
      "2  Duped and sold to a brothel, a young woman fea...   \n",
      "3  A major bank heist takes an unnerving turn whe...   \n",
      "4  When strangers Reet and Ruhan cross paths, the...   \n",
      "\n",
      "                                               genre         mood  \\\n",
      "0  ['Spy Movies', 'Hindi-Language Movies', 'Bolly...  Suspenseful   \n",
      "1  ['Hindi-Language Movies', 'Bollywood Movies', ...        Goofy   \n",
      "2  ['Hindi-Language Movies', 'Movies Based on Boo...  Provocative   \n",
      "3             ['Crime Movies', 'Action & Adventure']     Exciting   \n",
      "4  ['Hindi-Language Movies', 'Bollywood Movies', ...     Offbeat,   \n",
      "\n",
      "                                                cast  \\\n",
      "0  ['Sidharth Malhotra', 'Rashmika Mandanna', 'Pa...   \n",
      "1  ['Ranveer Singh', 'Varun Sharma', 'Pooja Hegde...   \n",
      "2  ['Alia Bhatt', 'Vijay Raaz', 'Seema Pahwa', 'A...   \n",
      "3  ['Ajith Kumar', 'Manju Warrier', 'Samuthirakan...   \n",
      "4  ['Tabu', 'Kartik Aaryan', 'Kiara Advani', 'Raj...   \n",
      "\n",
      "                           subtitles  \\\n",
      "0  ['English,', 'English,', 'Hindi']   \n",
      "1              ['English,', 'Hindi']   \n",
      "2              ['English,', 'Hindi']   \n",
      "3              ['English,', 'Hindi']   \n",
      "4              ['English,', 'Hindi']   \n",
      "\n",
      "                                               audio  \n",
      "0  ['English,', 'Hindi - Audio Description,', 'Hi...  \n",
      "1                               ['Hindi [Original]']  \n",
      "2                    ['Hindi [Original],', 'Telugu']  \n",
      "3                               ['Tamil [Original]']  \n",
      "4                               ['Hindi [Original]']  \n",
      "\n",
      "Dataset Info:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 560 entries, 0 to 559\n",
      "Data columns (total 10 columns):\n",
      " #   Column           Non-Null Count  Dtype \n",
      "---  ------           --------------  ----- \n",
      " 0   names            560 non-null    object\n",
      " 1   release_year     560 non-null    int64 \n",
      " 2   maturity_rating  560 non-null    object\n",
      " 3   duration         560 non-null    object\n",
      " 4   description      560 non-null    object\n",
      " 5   genre            560 non-null    object\n",
      " 6   mood             517 non-null    object\n",
      " 7   cast             560 non-null    object\n",
      " 8   subtitles        560 non-null    object\n",
      " 9   audio            560 non-null    object\n",
      "dtypes: int64(1), object(9)\n",
      "memory usage: 43.9+ KB\n",
      "\n",
      "Descriptive Statistics:\n",
      "       release_year\n",
      "count    560.000000\n",
      "mean    2016.521429\n",
      "std        6.282517\n",
      "min     1993.000000\n",
      "25%     2012.000000\n",
      "50%     2019.000000\n",
      "75%     2022.000000\n",
      "max     2023.000000\n",
      "\n",
      "Missing Values:\n",
      "names               0\n",
      "release_year        0\n",
      "maturity_rating     0\n",
      "duration            0\n",
      "description         0\n",
      "genre               0\n",
      "mood               43\n",
      "cast                0\n",
      "subtitles           0\n",
      "audio               0\n",
      "dtype: int64\n",
      "\n",
      "Unique Values per Column:\n",
      "names: 245\n",
      "release_year: 27\n",
      "maturity_rating: 5\n",
      "duration: 93\n",
      "description: 245\n",
      "genre: 127\n",
      "mood: 46\n",
      "cast: 240\n",
      "subtitles: 25\n",
      "audio: 43\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "\n",
    "df = pd.read_csv('Data/netfix_cleaned.csv')\n",
    "\n",
    "# Display the top 5 rows of the dataframe\n",
    "print(df.head())\n",
    "\n",
    "# Basic information about the dataset\n",
    "print(\"\\nDataset Info:\")\n",
    "df.info()\n",
    "\n",
    "# Descriptive statistics for numeric columns\n",
    "print(\"\\nDescriptive Statistics:\")\n",
    "print(df.describe())\n",
    "\n",
    "# Checking for missing values\n",
    "print(\"\\nMissing Values:\")\n",
    "print(df.isnull().sum())\n",
    "\n",
    "# Check the distribution of a categorical variable (if applicable)\n",
    "if 'category_column_name' in df.columns:\n",
    "    print(\"\\nCategory Distribution:\")\n",
    "    print(df['category_column_name'].value_counts())\n",
    "\n",
    "# Feel free to replace 'category_column_name' with an actual column name from your dataset\n",
    "# that you're interested to explore.\n",
    "\n",
    "# Another useful exploration is to see the number of unique values in each column\n",
    "print(\"\\nUnique Values per Column:\")\n",
    "for col in df.columns:\n",
    "    print(f\"{col}: {df[col].nunique()}\")\n",
    "\n",
    "# Displaying the distribution of numeric data\n",
    "# Importing necessary libraries for visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Set the visualisation style\n",
    "sns.set(style=\"whitegrid\")\n",
    "\n",
    "# Plotting the distribution of a numeric variable (if applicable)\n",
    "if 'numeric_column_name' in df.columns:\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    sns.histplot(df['numeric_column_name'], kde=True, bins=30)\n",
    "    plt.title('Distribution of Numeric Column')\n",
    "    plt.xlabel('Numeric Column Name')\n",
    "    plt.ylabel('Frequency')\n",
    "    plt.show()\n",
    "\n",
    "# Remember to replace 'numeric_column_name' with an actual numeric column name from your dataset.\n",
    "df[\"mood\"] = df[\"mood\"].fillna(\"Unlabeled\")\n",
    "# Extract hours and minutes from the duration column\n",
    "df['hours'] = df['duration'].str.extract('(\\d+)h').fillna(0)\n",
    "df['minutes'] = df['duration'].str.extract('(\\d+)m').fillna(0)\n",
    "\n",
    "# Convert the hours and minutes to integers\n",
    "df['hours'] = df['hours'].astype(int)\n",
    "df['minutes'] = df['minutes'].astype(int)\n",
    "\n",
    "# Calculate the total minutes\n",
    "df['total_minutes'] = df['hours'] * 60 + df['minutes']\n",
    "\n",
    "# Now you can drop the 'hours' and 'minutes' columns if they are not needed\n",
    "df = df.drop(['hours', 'minutes'], axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "class LSTMModel(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_dim, hidden_dim, output_dim):\n",
    "        super(LSTMModel, self).__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
    "        self.lstm = nn.LSTM(embedding_dim, hidden_dim, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_dim, output_dim)\n",
    "    \n",
    "    def forward(self, text):\n",
    "        embedded = self.embedding(text)\n",
    "        lstm_out, (hidden, cell) = self.lstm(embedded)\n",
    "        dense_outputs = self.fc(hidden[-1])\n",
    "        return dense_outputs\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Determing Vocab size and setting up features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "# Tokenize descriptions and build a vocabulary\n",
    "all_tokens = [token for description in df[\"description\"] for token in description.split()]\n",
    "vocab = Counter(all_tokens)\n",
    "vocab_size = len(vocab) + 1  # Adding 1 for 'unknown' token\n",
    "\n",
    "# Determine output dimensions based on the task\n",
    "output_dim = df['mood'].nunique()  # Adjust 'label' to your actual column name\n",
    "\n",
    "# Initialize the model, loss function, and optimizer\n",
    "model = LSTMModel(vocab_size, 100, 256, output_dim)\n",
    "criterion = nn.CrossEntropyLoss()  # Assuming a multi-class classification problem\n",
    "optimizer = optim.Adam(model.parameters())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6fb83ed833b34f03ab0e5b3fd0974803",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "42fb50e4a455484f85d1499e93ff1368",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ccb6b3da40f041beb15e16fbd077e00b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4ecc2de0f5f04beaac2313c9bfa85461",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/570 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1a482aaeb59548f1b6d33e69fbe9b168",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/440M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "BertModel(\n",
       "  (embeddings): BertEmbeddings(\n",
       "    (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "    (position_embeddings): Embedding(512, 768)\n",
       "    (token_type_embeddings): Embedding(2, 768)\n",
       "    (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (encoder): BertEncoder(\n",
       "    (layer): ModuleList(\n",
       "      (0-11): 12 x BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (pooler): BertPooler(\n",
       "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "    (activation): Tanh()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "from transformers import BertModel, BertTokenizer\n",
    "import torch\n",
    "\n",
    "# Load pre-trained model tokenizer (vocabulary)\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "\n",
    "# Load pre-trained model\n",
    "model = BertModel.from_pretrained('bert-base-uncased')\n",
    "model.eval()  # Set the model to evaluation mode\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenize and encode sentences in the DataFrame\n",
    "encoded_inputs = tokenizer(df[\"description\"].tolist(), padding=True, truncation=True, return_tensors=\"pt\", max_length=512)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to generate embeddings in batches\n",
    "def generate_embeddings(model, encoded_inputs, batch_size=10):\n",
    "    # Ensure inputs are on the same device as the model\n",
    "    device = next(model.parameters()).device\n",
    "    input_ids = encoded_inputs['input_ids'].to(device)\n",
    "    attention_mask = encoded_inputs['attention_mask'].to(device)\n",
    "    \n",
    "    model.to(device)\n",
    "    \n",
    "    embeddings = []\n",
    "    for i in range(0, len(input_ids), batch_size):\n",
    "        batch_input_ids = input_ids[i:i+batch_size]\n",
    "        batch_attention_mask = attention_mask[i:i+batch_size]\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            outputs = model(batch_input_ids, attention_mask=batch_attention_mask)\n",
    "        \n",
    "        # Use mean pooling to get a single vector for the sentence\n",
    "        batch_embeddings = outputs.last_hidden_state.mean(dim=1)\n",
    "        embeddings.append(batch_embeddings.cpu())\n",
    "    \n",
    "    # Concatenate all batch embeddings\n",
    "    embeddings = torch.cat(embeddings, dim=0)\n",
    "    return embeddings\n",
    "\n",
    "# Generate embeddings\n",
    "embeddings = generate_embeddings(model, encoded_inputs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([560, 768])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "import torch\n",
    "\n",
    "# Encode mood labels\n",
    "label_encoder = LabelEncoder()\n",
    "labels_encoded = label_encoder.fit_transform(df[\"mood\"])\n",
    "\n",
    "# Convert labels to a tensor\n",
    "labels_tensor = torch.tensor(labels_encoded, dtype=torch.long)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Split embeddings and labels into training and test sets\n",
    "embeddings_train, embeddings_test, labels_train, labels_test = train_test_split(\n",
    "    embeddings, labels_tensor, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# Convert splits to tensors\n",
    "embeddings_train_tensor = embeddings_train\n",
    "embeddings_test_tensor = embeddings_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MoodPredictor(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super(MoodPredictor, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, hidden_size)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(hidden_size, output_size)\n",
    "        self.softmax = nn.Softmax(dim=1)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        out = self.fc1(x)\n",
    "        out = self.relu(out)\n",
    "        out = self.fc2(out)\n",
    "        out = self.softmax(out)\n",
    "        return out\n",
    "\n",
    "# Determine the number of unique moods to set the output size\n",
    "output_size = len(torch.unique(labels_tensor))\n",
    "\n",
    "# Initialize the model\n",
    "model = MoodPredictor(input_size=embeddings.size(1), hidden_size=128, output_size=output_size)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/15], Loss: 3.7644\n",
      "Epoch [2/15], Loss: 3.7512\n",
      "Epoch [3/15], Loss: 3.7416\n",
      "Epoch [4/15], Loss: 3.7358\n",
      "Epoch [5/15], Loss: 3.7327\n",
      "Epoch [6/15], Loss: 3.7311\n",
      "Epoch [7/15], Loss: 3.7303\n",
      "Epoch [8/15], Loss: 3.7300\n",
      "Epoch [9/15], Loss: 3.7298\n",
      "Epoch [10/15], Loss: 3.7297\n",
      "Epoch [11/15], Loss: 3.7297\n",
      "Epoch [12/15], Loss: 3.7297\n",
      "Epoch [13/15], Loss: 3.7297\n",
      "Epoch [14/15], Loss: 3.7297\n",
      "Epoch [15/15], Loss: 3.7297\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 15\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    \n",
    "    # Convert embeddings and labels to Variables\n",
    "    inputs = torch.autograd.Variable(embeddings_train_tensor)\n",
    "    targets = torch.autograd.Variable(labels_train)\n",
    "\n",
    "    # Forward pass\n",
    "    outputs = model(inputs)\n",
    "    loss = criterion(outputs, targets)\n",
    "\n",
    "    # Backward and optimize\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the model on the test set: 17.86%\n"
     ]
    }
   ],
   "source": [
    "model.eval()  # Set the model to evaluation mode\n",
    "\n",
    "# Convert test embeddings and labels to Variables\n",
    "inputs_test = torch.autograd.Variable(embeddings_test_tensor)\n",
    "labels_test = torch.autograd.Variable(labels_test)\n",
    "\n",
    "with torch.no_grad():  # Inference mode, no gradients needed\n",
    "    outputs_test = model(inputs_test)\n",
    "    \n",
    "    # Get predictions from the maximum value\n",
    "    _, predicted_test = torch.max(outputs_test.data, 1)\n",
    "    \n",
    "    # Calculate the number of correctly predicted labels\n",
    "    correct_predictions = (predicted_test == labels_test).sum().item()\n",
    "    \n",
    "    # Calculate the accuracy\n",
    "    accuracy = correct_predictions / labels_test.size(0)\n",
    "    print(f'Accuracy of the model on the test set: {accuracy * 100:.2f}%')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
