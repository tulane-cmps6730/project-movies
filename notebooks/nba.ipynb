{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "import requests\n",
    "import time\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from scipy.sparse import hstack\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "nba_url = 'https://www.reddit.com/r/nba.json'\n",
    "lebron_url = 'https://www.reddit.com/r/lebron.json'\n",
    "micheal_url = 'https://www.reddit.com/r/michaeljordan.json'\n",
    "kobe_url = \"https://www.reddit.com/r/KobeBryant24.json\"\n",
    "header = {'User-agent': 'subreddit get requests'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define function to get num pages of posts from a subreddit, start collecting at a defined after\n",
    "def reddit_scraper(url, num, after = None):\n",
    "    posts = []\n",
    "    # loop through the num pages, each subreddit .json returns 25 posts \n",
    "    for page in range(num):\n",
    "        # initiate params modifier for posts if there no defined after\n",
    "        if after == None:\n",
    "            params = {}\n",
    "        # add in after id for each loop following to ensure no duplicate posts\n",
    "        else:\n",
    "            params = {'after': after}\n",
    "        # call our get request for the posts\n",
    "        res = requests.get(url, params=params, headers=header)\n",
    "        # check status code, 200 means posts were successfully downloaded\n",
    "        if res.status_code == 200:\n",
    "            # convert request to .json\n",
    "            new_json = res.json()\n",
    "            # extend list from the 'children' dictionary for each request\n",
    "            posts.extend(new_json['data']['children'])\n",
    "            # update after id\n",
    "            after = new_json['data']['after']\n",
    "        else:\n",
    "            # print status code if not 200\n",
    "            print(res.status_code)\n",
    "            break\n",
    "        # wait 1 second\n",
    "        time.sleep(1)\n",
    "        \n",
    "    # create a new dataframe with the 'data' from each post\n",
    "    new_df = pd.DataFrame([post['data'] for post in posts])\n",
    "    \n",
    "    # print final value of after\n",
    "    print(f'Final value of after parameter: {after}')\n",
    "    \n",
    "    # return the dataframe\n",
    "    return new_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make a function here that you can input a player name, and it will return a subreddit url for further df creation. Need some kind of regular expression usage to match player names with closest available subreddit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_url(player_name):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scraping subreddits for players. In the future, add a function here to type in a players name, and automatically return a dataframe associated with the subreddit of that players name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final value of after parameter: t3_zhky9j\n",
      "Final value of after parameter: t3_4uvx6f\n",
      "Final value of after parameter: t3_13m4sin\n"
     ]
    }
   ],
   "source": [
    "lebron_df = reddit_scraper(lebron_url, 10)\n",
    "jordan_df = reddit_scraper(micheal_url, 10)\n",
    "kobe_df = reddit_scraper(kobe_url, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features(df):\n",
    "    df = df[['selftext', 'title', 'subreddit']]\n",
    "    return df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_list = [extract_features(lebron_df), extract_features(jordan_df), extract_features(kobe_df)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def make_big_df_from_urls(player_url_list):\n",
    "    df_list = []\n",
    "    for url in player_url_list:\n",
    "        new_df = reddit_scraper(url)\n",
    "        df_list.append(new_df)\n",
    "\n",
    "    big_df = pd.concat(df_list, ignore_index=True)\n",
    "    big_df = extract_features(big_df)\n",
    "    return big_df\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "big_df = pd.concat(df_list, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cleaning Before We Featurize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "big_df = big_df.dropna(subset=['selftext', 'title'], how='all')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Featurizing Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# Initialize two separate vectorizers\n",
    "tfidf_title = TfidfVectorizer(max_df=0.95, min_df=2, max_features=5000)\n",
    "tfidf_selftext = TfidfVectorizer(max_df=0.95, min_df=2, max_features=5000)\n",
    "tfidf = TfidfVectorizer(max_df=0.95, min_df=2, max_features=5000)\n",
    "\n",
    "# Fit and transform separately\n",
    "title_vecs = tfidf_title.fit_transform(big_df['title'])\n",
    "selftext_vecs = tfidf_selftext.fit_transform(big_df['selftext'])\n",
    "\n",
    "# Combine the vectors\n",
    "X = hstack([title_vecs, selftext_vecs])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Experiment: Trying combining both text column into one and then vectorizing\n",
    "\n",
    "Conclusion: When using the combined column, most probable words for associated columns are more what you would expect. ie kobe for kobe. However, overall accuracy does go down"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [],
   "source": [
    "big_df['selftext'] = big_df['selftext'].fillna('')\n",
    "big_df['title'] = big_df['title'].fillna('')\n",
    "\n",
    "# Concatenate 'selftext' and 'title' into a new column 'combined_text'\n",
    "big_df['combined_text'] = big_df['title'] + \" \" + big_df['selftext']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {},
   "outputs": [],
   "source": [
    "big_df.to_csv('Kobe_Jordan_Lebron.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_vecs = tfidf.fit_transform(big_df['combined_text'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "X = hstack([combined_vecs])\n",
    "y = pd.get_dummies(big_df[\"subreddit\"]).values\n",
    "# Split the dataset into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "X_train\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "y\n",
    "y_train_1d = np.argmax(y_train, axis=1)\n",
    "y_test_1d = np.argmax(y_test, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Logistic Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.84      0.84        43\n",
      "           1       0.78      0.90      0.83        50\n",
      "           2       0.88      0.76      0.81        58\n",
      "\n",
      "    accuracy                           0.83       151\n",
      "   macro avg       0.83      0.83      0.83       151\n",
      "weighted avg       0.83      0.83      0.83       151\n",
      "\n",
      "Accuracy: 0.8278145695364238\n"
     ]
    }
   ],
   "source": [
    "# Initialize the Logistic Regression model\n",
    "# Solver 'lbfgs' works well for small datasets, but you might choose another based on your dataset size and characteristics\n",
    "# max_iter may need to be increased if the model fails to converge\n",
    "logistic_model = LogisticRegression(solver='lbfgs', max_iter=1000)\n",
    "\n",
    "# Fit the model to your data\n",
    "logistic_model.fit(X_train, y_train_1d)\n",
    "# Use the trained model to make predictions on the test set\n",
    "y_pred = logistic_model.predict(X_test)\n",
    "# Print the classification report\n",
    "print(classification_report(y_test_1d, y_pred))\n",
    "\n",
    "# Calculate and print the accuracy\n",
    "accuracy = accuracy_score(y_test_1d, y_pred)\n",
    "print(f\"Accuracy: {accuracy}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\n",
      "                precision    recall  f1-score   support\n",
      "\n",
      " KobeBryant24       0.88      0.81      0.84        43\n",
      "       lebron       0.75      0.92      0.83        50\n",
      "michaeljordan       0.90      0.78      0.83        58\n",
      "\n",
      "     accuracy                           0.83       151\n",
      "    macro avg       0.84      0.84      0.84       151\n",
      " weighted avg       0.84      0.83      0.83       151\n",
      "\n",
      "Accuracy: 0.8344370860927153\n"
     ]
    }
   ],
   "source": [
    "subreddit_names = pd.get_dummies(big_df[\"subreddit\"]).columns\n",
    "y_test_categories = np.argmax(y_test, axis=1)\n",
    "# y_pred_categories is already in the correct format if LogisticRegression.predict() was used\n",
    "y_pred_categories = y_pred  # Assuming y_pred is the output from logistic_model.predict(X_test)\n",
    "\n",
    "# Continue with the Accuracy and Classification Report\n",
    "print(\"Classification Report:\\n\", classification_report(y_test_categories, y_pred_categories, target_names=subreddit_names))\n",
    "print(\"Accuracy:\", accuracy_score(y_test_categories, y_pred_categories))\n",
    "\n",
    "# For displaying samples, ensure you adjust according to your DataFrame's indexing if needed\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Instance 1:\n",
      "Title: Who Embarrassed Michael Jordan The Worst Shaq or Allen Iverson\n",
      "Selftext: \n",
      "Predicted Subreddit: KobeBryant24\n",
      "Actual Subreddit: KobeBryant24\n",
      "------------------------------------------------------------\n",
      "Instance 2:\n",
      "Title: The coin flip that changed the fate of Magic Johnson and Michael Jordan - Epicbuzzer\n",
      "Selftext: \n",
      "Predicted Subreddit: KobeBryant24\n",
      "Actual Subreddit: KobeBryant24\n",
      "------------------------------------------------------------\n",
      "Instance 3:\n",
      "Title: During timeout, LeBron James working a bit on his footwork in the post. LeBron also instructing Max Christie on various spin moves\n",
      "Selftext: \n",
      "Predicted Subreddit: michaeljordan\n",
      "Actual Subreddit: michaeljordan\n",
      "------------------------------------------------------------\n",
      "Instance 4:\n",
      "Title: Eigener edit\n",
      "Selftext: \n",
      "Predicted Subreddit: lebron\n",
      "Actual Subreddit: lebron\n",
      "------------------------------------------------------------\n",
      "Instance 5:\n",
      "Title: Im Michael Now\n",
      "Selftext: \n",
      "Predicted Subreddit: lebron\n",
      "Actual Subreddit: lebron\n",
      "------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "# Continuing from the previous setup, where test_indices is assumed to hold indices of X_test in big_df\n",
    "# Here we'll select a few specific indices for demonstration. In practice, you'd use actual indices from X_test.\n",
    "\n",
    "# Sample a few indices for display, ensure you have a method to relate X_test back to big_df\n",
    "sample_indices = random.sample(test_indices, 5)\n",
    "\n",
    "for i, idx in enumerate(sample_indices):\n",
    "    # Extracting both 'title' and 'selftext' from the original DataFrame\n",
    "    original_title = big_df.iloc[idx]['title']  # Title text\n",
    "    original_text = big_df.iloc[idx]['selftext']  # Selftext\n",
    "    predicted_label = subreddit_names[y_pred_categories[i]]  # Predicted subreddit\n",
    "    actual_label = subreddit_names[y_test_categories[i]]  # Actual subreddit\n",
    "    \n",
    "    print(f\"Instance {i+1}:\")\n",
    "    print(f\"Title: {original_title}\")\n",
    "    print(f\"Selftext: {original_text}\")\n",
    "    print(f\"Predicted Subreddit: {predicted_label}\")\n",
    "    print(f\"Actual Subreddit: {actual_label}\")\n",
    "    print(\"-\" * 60)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class 0: Most influential words\n",
      " slowly (Coefficient: 0.9162)\n",
      " braves (Coefficient: -1.0524)\n",
      " clear (Coefficient: -1.1637)\n",
      " chng (Coefficient: -1.3002)\n",
      " championships (Coefficient: 1.4877)\n",
      " broke (Coefficient: -1.5943)\n",
      " scoring (Coefficient: 1.6822)\n",
      " 86 (Coefficient: 1.6947)\n",
      " came (Coefficient: -2.0552)\n",
      " business (Coefficient: 4.3713)\n",
      "----------------------------------------\n",
      "Class 1: Most influential words\n",
      " fails (Coefficient: 0.8564)\n",
      " send (Coefficient: 0.9144)\n",
      " 86 (Coefficient: -1.0151)\n",
      " chng (Coefficient: -1.0944)\n",
      " bucket (Coefficient: 1.2493)\n",
      " clear (Coefficient: -1.4564)\n",
      " broke (Coefficient: -1.8793)\n",
      " braves (Coefficient: 2.1718)\n",
      " business (Coefficient: -2.4146)\n",
      " came (Coefficient: 3.5274)\n",
      "----------------------------------------\n",
      "Class 2: Most influential words\n",
      " bag (Coefficient: 0.7625)\n",
      " dm (Coefficient: 0.7654)\n",
      " fails (Coefficient: -0.8226)\n",
      " scoring (Coefficient: -0.8343)\n",
      " braves (Coefficient: -1.1194)\n",
      " came (Coefficient: -1.4721)\n",
      " business (Coefficient: -1.9568)\n",
      " chng (Coefficient: 2.3946)\n",
      " clear (Coefficient: 2.6201)\n",
      " broke (Coefficient: 3.4736)\n",
      "----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Ensure you're using the correct vectorizer instance that was fit on the training data\n",
    "feature_names = tfidf.get_feature_names_out()\n",
    "\n",
    "# Assuming logistic_model is your trained model\n",
    "num_classes = logistic_model.coef_.shape[0]\n",
    "top_features = 10\n",
    "\n",
    "for class_index in range(num_classes):\n",
    "    coefficients = logistic_model.coef_[class_index]\n",
    "    # Ensure we only consider as many features as we have names for\n",
    "    top_indices = np.argsort(np.abs(coefficients))[-top_features:]\n",
    "    \n",
    "    print(f\"Class {class_index}: Most influential words\")\n",
    "    for index in top_indices:\n",
    "        # Safeguard against out-of-bounds access\n",
    "        if index < len(feature_names):\n",
    "            print(f\" {feature_names[index]} (Coefficient: {coefficients[index]:.4f})\")\n",
    "        else:\n",
    "            print(\" Index out of bounds, skipped.\")\n",
    "    print(\"-\" * 40)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now Trying With Neural Net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from scipy.sparse import csr_matrix\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "# Function to convert sparse matrix to tensor\n",
    "def sparse_to_tensor(sparse_matrix):\n",
    "    sparse_matrix = sparse_matrix.tocoo().astype(np.float32)\n",
    "    indices = torch.from_numpy(\n",
    "        np.vstack((sparse_matrix.row, sparse_matrix.col)).astype(np.int64)\n",
    "    )\n",
    "    values = torch.from_numpy(sparse_matrix.data)\n",
    "    shape = torch.Size(sparse_matrix.shape)\n",
    "    return torch.sparse_coo_tensor(indices, values, shape)\n",
    "\n",
    "# Convert X and y to PyTorch tensors\n",
    "X_train_tensor = sparse_to_tensor(X_train)\n",
    "X_test_tensor = sparse_to_tensor(X_test)\n",
    "y_train_tensor = torch.from_numpy(y_train.astype(np.float32))\n",
    "y_test_tensor = torch.from_numpy(y_test.astype(np.float32))\n",
    "\n",
    "# Create TensorDatasets and DataLoaders\n",
    "train_dataset = TensorDataset(X_train_tensor.to_dense(), y_train_tensor)\n",
    "test_dataset = TensorDataset(X_test_tensor.to_dense(), y_test_tensor)\n",
    "\n",
    "batch_size = 64  # Adjust based on your computational resources\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class TextClassifier(nn.Module):\n",
    "    def __init__(self, input_dim, output_dim):\n",
    "        super(TextClassifier, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_dim, 512)\n",
    "        self.fc2 = nn.Linear(512, 128)\n",
    "        self.fc3 = nn.Linear(128, output_dim)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return F.softmax(x, dim=1)  # Softmax applied at the output layer\n",
    "\n",
    "# Determine input and output dimensions\n",
    "input_dim = X_train.shape[1]\n",
    "output_dim = y_train.shape[1]  # Number of classes\n",
    "\n",
    "# Initialize the model\n",
    "model = TextClassifier(input_dim, output_dim)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 1.092287540435791\n",
      "Epoch 2, Loss: 1.0435715913772583\n",
      "Epoch 3, Loss: 0.9451636672019958\n",
      "Epoch 4, Loss: 0.7866892218589783\n",
      "Epoch 5, Loss: 0.6858813762664795\n",
      "Epoch 6, Loss: 0.5712226629257202\n",
      "Epoch 7, Loss: 0.649848997592926\n",
      "Epoch 8, Loss: 0.5653098821640015\n",
      "Epoch 9, Loss: 0.618776798248291\n",
      "Epoch 10, Loss: 0.5668134689331055\n"
     ]
    }
   ],
   "source": [
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Training loop\n",
    "epochs = 10  # Number of epochs to train for\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    for X_batch, y_batch in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        predictions = model(X_batch)\n",
    "        loss = criterion(predictions, torch.max(y_batch, 1)[1])  # Assuming y_batch is one-hot encoded\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    \n",
    "    print(f\"Epoch {epoch+1}, Loss: {loss.item()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 74.83%\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model\n",
    "model.eval()  # Set the model to evaluation mode\n",
    "\n",
    "# Tracking variables\n",
    "correct_predictions = 0\n",
    "total_predictions = 0\n",
    "\n",
    "# No gradient updates needed for evaluation\n",
    "with torch.no_grad():\n",
    "    for X_batch, y_batch in test_loader:\n",
    "        predictions = model(X_batch)\n",
    "        _, predicted_labels = torch.max(predictions, 1)\n",
    "        _, actual_labels = torch.max(y_batch, 1)\n",
    "        \n",
    "        total_predictions += y_batch.size(0)\n",
    "        correct_predictions += (predicted_labels == actual_labels).sum().item()\n",
    "\n",
    "accuracy = correct_predictions / total_predictions\n",
    "print(f'Accuracy: {accuracy * 100:.2f}%')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "KNN classifier, performed the worst at the moment "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 43.71%\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Assuming y_train and y_test are one-hot encoded, convert them back to label-encoded format\n",
    "y_train_labels = np.argmax(y_train, axis=1)\n",
    "y_test_labels = np.argmax(y_test, axis=1)\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "# Initialize the KNN classifier\n",
    "knn = KNeighborsClassifier(n_neighbors=5)  # You can adjust the number of neighbors\n",
    "\n",
    "# Fit the model to the training data\n",
    "# Note: For high-dimensional sparse data, converting to dense might be memory-intensive\n",
    "# Consider using TruncatedSVD or similar techniques to reduce dimensionality if necessary\n",
    "knn.fit(X_train, y_train_labels)\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Predict the labels for the test set\n",
    "y_pred = knn.predict(X_test)\n",
    "\n",
    "# Calculate and print the accuracy\n",
    "accuracy = accuracy_score(y_test_labels, y_pred)\n",
    "print(f'Accuracy: {accuracy * 100:.2f}%')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 80.79%\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Initialize the Multinomial Naive Bayes classifier\n",
    "mnb = MultinomialNB(alpha=4)\n",
    "\n",
    "# Fit the classifier to the training data\n",
    "# Note: MultinomialNB works with sparse matrices, so there's no need to convert them to dense\n",
    "mnb.fit(X_train, y_train_labels)\n",
    "# Predict the labels for the test set\n",
    "y_pred = mnb.predict(X_test)\n",
    "\n",
    "# Calculate and print the accuracy\n",
    "accuracy = accuracy_score(y_test_labels, y_pred)\n",
    "print(f'Accuracy: {accuracy * 100:.2f}%')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "KNN, Logistic Regression, and Neural Net All performed similarily. Naive Bayes performed the best."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_names = tfidf.get_feature_names_out()\n",
    "log_probabilities = mnb.feature_log_prob_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KobeBryant24: Most influential words\n",
      "  business: -5.3440\n",
      "----------------------------------------\n",
      "lebron: Most influential words\n",
      "  came: -5.4222\n",
      "----------------------------------------\n",
      "michaeljordan: Most influential words\n",
      "  broke: -5.6316\n",
      "----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "def print_top_words_per_class(classifier, vectorizer, class_labels, num_top_words=10):\n",
    "    \"\"\"\n",
    "    Prints the top words that are most indicative of each class according to the classifier,\n",
    "    along with the actual class names.\n",
    "\n",
    "    Parameters:\n",
    "    - classifier: A trained Multinomial Naive Bayes classifier.\n",
    "    - vectorizer: The vectorizer used to transform the text data.\n",
    "    - class_labels: A list of class names corresponding to the classifier's classes.\n",
    "    - num_top_words: The number of top words to display for each class.\n",
    "    \"\"\"\n",
    "    feature_names = vectorizer.get_feature_names_out()\n",
    "    log_probabilities = classifier.feature_log_prob_\n",
    "    \n",
    "    for i, class_log_prob in enumerate(log_probabilities):\n",
    "        class_name = class_labels[i]  # Use the actual class name\n",
    "        print(f\"{class_name}: Most influential words\")\n",
    "        top_indices = class_log_prob.argsort()[-num_top_words:]\n",
    "        \n",
    "        for index in reversed(top_indices):  # Print from highest to lowest\n",
    "            if index < len(feature_names):  # Check index to ensure within bounds\n",
    "                print(f\"  {feature_names[index]}: {class_log_prob[index]:.4f}\")\n",
    "            else:\n",
    "                print(\" Index out of bounds, skipped.\")\n",
    "        print(\"-\" * 40)\n",
    "\n",
    "# To get the class labels (subreddit names) in the correct order\n",
    "class_labels = list(pd.get_dummies(big_df[\"subreddit\"]).columns)\n",
    "\n",
    "# Example usage\n",
    "print_top_words_per_class(mnb, tfidf, class_labels, num_top_words=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [],
   "source": [
    "def input_sentence_to_prediction(text_sentence, model):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [],
   "source": [
    "def input_sentence_to_prediction(model, tfidf_title, tfidf_selftext, text_title, text_sentence):\n",
    "    \"\"\"\n",
    "    Converts text input into a prediction using the specified model and vectorizers.\n",
    "\n",
    "    Parameters:\n",
    "    - model: The trained classification model.\n",
    "    - tfidf_title: The TF-IDF vectorizer used during training for titles.\n",
    "    - tfidf_selftext: The TF-IDF vectorizer used during training for selftext.\n",
    "    - text_title: The input text title to predict.\n",
    "    - text_sentence: The input text sentence (selftext) to predict.\n",
    "    \n",
    "    Returns:\n",
    "    - The predicted class for the input text.\n",
    "    \"\"\"\n",
    "    # Vectorize the input text title and text sentence using the corresponding TF-IDF vectorizers\n",
    "    title_vec = tfidf_title.transform([text_title])\n",
    "    sentence_vec = tfidf_selftext.transform([text_sentence])\n",
    "    \n",
    "    # Combine the vectors to match the training data structure\n",
    "    combined_input_vec = hstack([title_vec, sentence_vec])\n",
    "    \n",
    "    # Predict the class for the combined input vector\n",
    "    prediction = model.predict(combined_input_vec)\n",
    "    \n",
    "    return prediction\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted class: KobeBryant24\n"
     ]
    }
   ],
   "source": [
    "model = mnb  # Your trained MultinomialNB model\n",
    "\n",
    "text_title = \"Things \"  # Example text for the title\n",
    "text_sentence = \"Lebron Lebron kobe kobe lebron kobe\" \n",
    "prediction = input_sentence_to_prediction(model, tfidf_title, tfidf_selftext, text_title, text_sentence)\n",
    "\n",
    "# Assuming your model outputs numerical class labels, you might want to map these back to class names.\n",
    "# If `class_labels` is a list of class names in the order they were encoded:\n",
    "predicted_class = class_labels[prediction[0]]  # prediction[0] because model.predict returns an array of predictions\n",
    "print(\"Predicted class:\", predicted_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
